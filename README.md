# visual-question-answering


# VQA Datasets
- [VQA](https://visualqa.org/download.html) is a new dataset containing open-ended questions about images.
- [VizWiz-VQA](https://vizwiz.org/tasks-and-datasets/vqa/) is visual question answering (VQA) dataset curated from people who are blind.
- [OK-VQA](https://okvqa.allenai.org/download.html) is a dataset for visual question answering that requires methods which can draw upon outside knowledge to answer questions.

# Tutorials
- [Deep Learning and Visual Question Answering](https://towardsdatascience.com/deep-learning-and-visual-question-answering-c8c8093941bc)
- [Vanilla VQA: An introduction to Visual Question Answering](https://medium.com/ai2-blog/vanilla-vqa-adcaaaa94336)


# Learning Materials from YouTube
[Visual Question Answering (VQA) by Devi Parikh](https://www.youtube.com/watch?v=ElZADFTer4I)

[Devi Parikh - Words, Pictures, and Common Sense - The Frontiers of Machine Learning](https://www.youtube.com/watch?v=wmcmBpfaQaU)

[VQA-Dial Workshop 2019](https://youtube.com/playlist?list=PL-fZD610i7yAjD7jU5sQkrx5esgGQ55yi)

# Demos
[CloudCV VQA](http://vqa.cloudcv.org/) created by students and faculty from Machine Learning and Perception Lab at Virginia Tech.

# Papers
[VQA: Visual Question Answering](https://arxiv.org/abs/1505.00468)

